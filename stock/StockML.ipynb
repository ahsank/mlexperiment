{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"StockML.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNnekZQ8AdoZ9NGOSh3ifkG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRWFgIbnzajB","executionInfo":{"status":"ok","timestamp":1642411401630,"user_tz":480,"elapsed":10143,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"f6cf5af0-211c-4f25-f580-7e668a5cbe66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting yahoo_fin\n","  Downloading yahoo_fin-0.8.9.1-py3-none-any.whl (10 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from yahoo_fin) (1.1.5)\n","Collecting requests-html\n","  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n","Collecting feedparser\n","  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 4.2 MB/s \n","\u001b[?25hCollecting sgmllib3k\n","  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (1.19.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->yahoo_fin) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->yahoo_fin) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yahoo_fin) (2.10)\n","Collecting pyppeteer>=0.0.14\n","  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n","\u001b[K     |████████████████████████████████| 83 kB 1.9 MB/s \n","\u001b[?25hCollecting parse\n","  Downloading parse-1.19.0.tar.gz (30 kB)\n","Collecting pyquery\n","  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n","Collecting fake-useragent\n","  Downloading fake-useragent-0.1.11.tar.gz (13 kB)\n","Collecting w3lib\n","  Downloading w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (from requests-html->yahoo_fin) (0.0.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.62.3)\n","Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.10.0)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 42.0 MB/s \n","\u001b[?25hCollecting websockets<11.0,>=10.0\n","  Downloading websockets-10.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (111 kB)\n","\u001b[K     |████████████████████████████████| 111 kB 38.4 MB/s \n","\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n","Collecting pyee<9.0.0,>=8.1.0\n","  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.7.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.10.0.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->requests-html->yahoo_fin) (4.6.3)\n","Collecting cssselect>0.7.9\n","  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyquery->requests-html->yahoo_fin) (4.2.6)\n","Building wheels for collected packages: fake-useragent, parse, sgmllib3k\n","  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-py3-none-any.whl size=13502 sha256=0df54927c1222d9f48b4dd5abde8dbce5cb1a45598c11e2d5ce7dc6d9cae2cd1\n","  Stored in directory: /root/.cache/pip/wheels/ed/f7/62/50ab6c9a0b5567267ab76a9daa9d06315704209b2c5d032031\n","  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=2d3fa115dd6f8a3df187deab69f7c3fb37c60de0339616cd35b325a6b2dc6ff6\n","  Stored in directory: /root/.cache/pip/wheels/9c/aa/cc/f2228050ccb40f22144b073f15a2c84f11204f29fc0dce028e\n","  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=a45bf061d3c4c1876034ebaa88b002deea026d25c4bb65ed98538c3970620235\n","  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n","Successfully built fake-useragent parse sgmllib3k\n","Installing collected packages: websockets, urllib3, pyee, cssselect, w3lib, sgmllib3k, pyquery, pyppeteer, parse, fake-useragent, requests-html, feedparser, yahoo-fin\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed cssselect-1.1.0 fake-useragent-0.1.11 feedparser-6.0.8 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-1.4.3 requests-html-0.10.0 sgmllib3k-1.0.0 urllib3-1.25.11 w3lib-1.22.0 websockets-10.1 yahoo-fin-0.8.9.1\n"]}],"source":["pip install yahoo_fin"]},{"cell_type":"code","source":["mkdir -p data results log\n"],"metadata":{"id":"0MuPGKaH3W59","executionInfo":{"status":"ok","timestamp":1642411404083,"user_tz":480,"elapsed":204,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import tradealg"],"metadata":{"id":"vcZWxbn91Lwl","executionInfo":{"status":"ok","timestamp":1642353001974,"user_tz":480,"elapsed":3362,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","import imp\n"],"metadata":{"id":"poUsz23y1PR3","executionInfo":{"status":"ok","timestamp":1642352662530,"user_tz":480,"elapsed":259,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Pv5TDe_02fud","executionInfo":{"status":"ok","timestamp":1642352740344,"user_tz":480,"elapsed":247,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"0c627243-2ab4-40c4-b4dc-0a8039f2c26d"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["imp.reload(tradealg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMsWUEaq2QRo","executionInfo":{"status":"ok","timestamp":1642352697782,"user_tz":480,"elapsed":261,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"1d582c1d-6407-4daa-bda9-04c13179a900"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'tradealg' from '/content/tradealg.py'>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from yahoo_fin import stock_info as si\n","from collections import deque\n","\n","import os\n","import numpy as np\n","import pandas as pd\n","import random\n","import time\n","from tensorflow.keras.layers import LSTM\n","import matplotlib.pyplot as plt"],"metadata":{"id":"4LpuYsu4h3lA","executionInfo":{"status":"ok","timestamp":1642411412635,"user_tz":480,"elapsed":3432,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","def prepare():\n","    # set seed, so we can get the same results after rerunning several times\n","    np.random.seed(314)\n","    tf.random.set_seed(314)\n","    random.seed(314)\n","\n","\n","def shuffle_in_unison(a, b):\n","    # shuffle two arrays in the same way\n","    state = np.random.get_state()\n","    np.random.shuffle(a)\n","    np.random.set_state(state)\n","    np.random.shuffle(b)\n","\n","def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n","                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n","    \"\"\"\n","    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n","    Params:\n","        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n","        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n","        scale (bool): whether to scale prices from 0 to 1, default is True\n","        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n","        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n","        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n","            to False will split datasets in a random way\n","        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n","        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n","    \"\"\"\n","    # see if ticker is already a loaded stock from yahoo finance\n","    if isinstance(ticker, str):\n","        # load it from yahoo_fin library\n","        df = si.get_data(ticker)\n","    elif isinstance(ticker, pd.DataFrame):\n","        # already loaded, use it directly\n","        df = ticker\n","    else:\n","        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n","    # this will contain all the elements we want to return from this function\n","    result = {}\n","    # we will also return the original dataframe itself\n","    result['df'] = df.copy()\n","    # make sure that the passed feature_columns exist in the dataframe\n","    for col in feature_columns:\n","        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n","    # add date as a column\n","    if \"date\" not in df.columns:\n","        df[\"date\"] = df.index\n","    if scale:\n","        column_scaler = {}\n","        # scale the data (prices) from 0 to 1\n","        for column in feature_columns:\n","            scaler = preprocessing.MinMaxScaler()\n","            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n","            column_scaler[column] = scaler\n","        # add the MinMaxScaler instances to the result returned\n","        result[\"column_scaler\"] = column_scaler\n","    # add the target column (label) by shifting by `lookup_step`\n","    df['future'] = df['adjclose'].shift(-lookup_step)\n","    # last `lookup_step` columns contains NaN in future column\n","    # get them before droping NaNs\n","    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n","    # drop NaNs\n","    df.dropna(inplace=True)\n","    sequence_data = []\n","    sequences = deque(maxlen=n_steps)\n","    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n","        sequences.append(entry)\n","        if len(sequences) == n_steps:\n","            sequence_data.append([np.array(sequences), target])\n","    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n","    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n","    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n","    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n","    last_sequence = np.array(last_sequence).astype(np.float32)\n","    # add to result\n","    result['last_sequence'] = last_sequence\n","    # construct the X's and y's\n","    X, y = [], []\n","    for seq, target in sequence_data:\n","        X.append(seq)\n","        y.append(target)\n","    # convert to numpy arrays\n","    X = np.array(X)\n","    y = np.array(y)\n","    if split_by_date:\n","        # split the dataset into training & testing sets by date (not randomly splitting)\n","        train_samples = int((1 - test_size) * len(X))\n","        result[\"X_train\"] = X[:train_samples]\n","        result[\"y_train\"] = y[:train_samples]\n","        result[\"X_test\"]  = X[train_samples:]\n","        result[\"y_test\"]  = y[train_samples:]\n","        if shuffle:\n","            # shuffle the datasets for training (if shuffle parameter is set)\n","            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n","            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n","    else:    \n","        # split the dataset randomly\n","        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n","    # get the list of test set dates\n","    dates = result[\"X_test\"][:, -1, -1]\n","    # retrieve test features from the original dataframe\n","    result[\"test_df\"] = result[\"df\"].loc[dates]\n","    # remove duplicated dates in the testing dataframe\n","    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n","    # remove dates from the training/testing sets & convert to float32\n","    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n","    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n","    return result\n","\n","def get_final_df(model, data, scale, lookup_step, trade):\n","    \"\"\"\n","    This function takes the `model` and `data` dict to \n","    construct a final dataframe that includes the features along \n","    with true and predicted prices of the testing dataset\n","    \"\"\"\n","    X_test = data[\"X_test\"]\n","    y_test = data[\"y_test\"]\n","    # perform prediction and get prices\n","    y_pred = model.predict(X_test)\n","    if scale:\n","        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n","        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n","    test_df = data[\"test_df\"]\n","    # add predicted future prices to the dataframe\n","    test_df[f\"adjclose_{lookup_step}\"] = y_pred\n","    # add true future prices to the dataframe\n","    test_df[f\"true_adjclose_{lookup_step}\"] = y_test\n","    # sort the dataframe by date\n","    test_df.sort_index(inplace=True)\n","    final_df = test_df\n","    # add the buy profit column\n","    final_df[\"buy_profit\"] = list(map(trade.buy_profit, \n","                                    final_df[\"adjclose\"], \n","                                    final_df[f\"adjclose_{lookup_step}\"], \n","                                    final_df[f\"true_adjclose_{lookup_step}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    # add the sell profit column\n","    final_df[\"sell_profit\"] = list(map(trade.sell_profit, \n","                                    final_df[\"adjclose\"], \n","                                    final_df[f\"adjclose_{lookup_step}\"], \n","                                    final_df[f\"true_adjclose_{lookup_step}\"])\n","                                    # since we don't have profit for last sequence, add 0's\n","                                    )\n","    return final_df\n","\n","\n","class TradingResult:\n","    def __init__(self, model, prepdata, lossn):\n","        self.model = model\n","        self.pdata = prepdata\n","        self.data = prepdata.data\n","        self.LOSSN = lossn\n","        \n","    def predict(self):\n","        # retrieve the last sequence from data\n","        last_sequence = self.data[\"last_sequence\"][-self.pdata.N_STEPS:]\n","        # expand dimension\n","        last_sequence = np.expand_dims(last_sequence, axis=0)\n","        # get the prediction (scaled from 0 to 1)\n","        prediction = self.model.predict(last_sequence)\n","        # get the price (by inverting the scaling)\n","        if self.pdata.SCALE:\n","            predicted_price = self.data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n","        else:\n","            predicted_price = prediction[0][0]\n","        return predicted_price\n","\n","    def eval(self, trade):\n","        # evaluate the model\n","        loss, mae = self.model.evaluate(self.data[\"X_test\"], self.data[\"y_test\"], verbose=0)\n","        # calculate the mean absolute error (inverse scaling)\n","        if self.pdata.SCALE:\n","            self.mean_absolute_error = self.data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n","        else:\n","            self.mean_absolute_error = mae\n","            \n","        # get the final dataframe for the testing set\n","        final_df = get_final_df(self.model, self.data, self.pdata.SCALE, self.pdata.LOOKUP_STEP, trade)\n","        # predict the future price\n","        self.future_price = self.predict()\n","        # we calculate the accuracy by counting the number of positive profits\n","        self.accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n","        # calculating total buy & sell profit\n","        self.total_buy_profit  = final_df[\"buy_profit\"].sum()\n","        self.total_sell_profit = final_df[\"sell_profit\"].sum()\n","        # total profit by adding sell & buy together\n","        self.total_profit = self.total_buy_profit + self.total_sell_profit\n","        # dividing total profit by number of testing samples (number of trades)\n","        self.profit_per_trade = self.total_profit / len(final_df)\n","        self.final_df = final_df\n","        self.loss = loss\n","\n","    def print(self):\n","        # printing metrics\n","        print(f\"Ticker {self.pdata.ticker}\")\n","        print(f\"Future price after {self.pdata.LOOKUP_STEP} days is {self.future_price:.2f}$\")\n","        print(f\"{self.LOSSN}_loss:\", self.loss)\n","        print(\"Mean Absolute Error:\", self.mean_absolute_error)\n","        print(\"Accuracy score:\", self.accuracy_score)\n","        print(\"Total buy profit:\", self.total_buy_profit)\n","        print(\"Total sell profit:\", self.total_sell_profit)\n","        print(\"Total profit:\", self.total_profit)\n","        print(\"Profit per trade:\", self.profit_per_trade)\n","        \n","class PreparedData:\n","    def __init__(self, ticker):\n","        # Window size or the sequence length\n","        self.N_STEPS = 50\n","\t# Lookup step, 1 is the next day\n","        self.LOOKUP_STEP = 15\n","        # whether to scale feature columns & output price as well\n","        self.SCALE = True\n","        self.scale_str = f\"sc-{int(self.SCALE)}\"\n","        # whether to shuffle the dataset\n","        self.SHUFFLE = True\n","        self.shuffle_str = f\"sh-{int(self.SHUFFLE)}\"\n","        # whether to split the training/testing set by date\n","        self.SPLIT_BY_DATE = False\n","        self.split_by_date_str = f\"sbd-{int(self.SPLIT_BY_DATE)}\"\n","        # test ratio size, 0.2 is 20%\n","        self.TEST_SIZE = 0.2\n","        # features to use\n","        self.FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n","        self.ticker = ticker\n","        # date now\n","        self.date_now = time.strftime(\"%Y-%m-%d\")        \n","        self.ticker_data_filename = os.path.join(\"data\", f\"{self.ticker}_{self.date_now}.csv\")\n","        self.data_prefix = f\"{self.date_now}_{self.ticker}-{self.shuffle_str}-{self.scale_str}-{self.split_by_date_str}-seq-{self.N_STEPS}-step-{self.LOOKUP_STEP}\"\n","        \n","    def prepare(self,  df):\n","        # load the data\n","        self.data = load_data(df, self.N_STEPS, scale=self.SCALE, split_by_date=self.SPLIT_BY_DATE, \n","                shuffle=self.SHUFFLE, lookup_step=self.LOOKUP_STEP, test_size=self.TEST_SIZE, \n","                feature_columns=self.FEATURE_COLUMNS)\n","\n","        # save the dataframe\n","        self.data[\"df\"].to_csv(self.ticker_data_filename)\n","\n","\n","def fetch_data(ticker):\n","# see if ticker is already a loaded stock from yahoo finance\n","    if isinstance(ticker, str):\n","        # load it from yahoo_fin library\n","        df = si.get_data(ticker)\n","    elif isinstance(ticker, pd.DataFrame):\n","        # already loaded, use it directly\n","        df = ticker\n","    else:\n","        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n","    return df\n","\n","\n","def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n","                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n","    model = Sequential()\n","    for i in range(n_layers):\n","        if i == 0:\n","            # first layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n","            else:\n","                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n","        elif i == n_layers - 1:\n","            # last layer\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=False)))\n","            else:\n","                model.add(cell(units, return_sequences=False))\n","        else:\n","            # hidden layers\n","            if bidirectional:\n","                model.add(Bidirectional(cell(units, return_sequences=True)))\n","            else:\n","                model.add(cell(units, return_sequences=True))\n","        # add dropout after each layer\n","        model.add(Dropout(dropout))\n","    model.add(Dense(1, activation=\"linear\"))\n","    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n","    return model\n","\n","\n","import os\n","import time\n","from tensorflow.keras.layers import LSTM\n","\n","EPOCHS = 20\n","\n","class RNNModel:\n","    def __init__(self):\n","        self.date_now = time.strftime(\"%Y-%m-%d\")\n","        ### model parameters\n","        self.N_LAYERS = 2\n","        # LSTM cell\n","        self.CELL = LSTM\n","        # 256 LSTM neurons\n","        self.UNITS = 256\n","        # 40% dropout\n","        self.DROPOUT = 0.4\n","        # whether to use bidirectional RNNs\n","        self.BIDIRECTIONAL = False\n","        ### training parameters\n","        # mean absolute error loss\n","        # LOSS = \"mae\"\n","        # huber loss\n","        self.LOSS = \"huber_loss\"\n","        self.OPTIMIZER = \"adam\"\n","        self.BATCH_SIZE = 64\n","        self.EPOCHS = EPOCHS # 500\n","\n","    def create(self, prepdata):\n","        # model name to save, making it as unique as possible based on parameters\n","        self.model_name = f\"{prepdata.data_prefix}-model-{self.LOSS}-{self.OPTIMIZER}-{self.CELL.__name__}-layers-{self.N_LAYERS}-units-{self.UNITS}\"\n","        if self.BIDIRECTIONAL:\n","            self.model_name += \"-b\"\n","\n","        # create these folders if they does not exist\n","        if not os.path.isdir(\"results\"):\n","            os.mkdir(\"results\")\n","        if not os.path.isdir(\"logs\"):\n","            os.mkdir(\"logs\")\n","        if not os.path.isdir(\"data\"):\n","            os.mkdir(\"data\")\n","\n","        self.model = create_model(prepdata.N_STEPS, len(prepdata.FEATURE_COLUMNS), loss=self.LOSS, units=self.UNITS, cell=self.CELL, n_layers=self.N_LAYERS,\n","                    dropout=self.DROPOUT, optimizer=self.OPTIMIZER, bidirectional=self.BIDIRECTIONAL)\n","        # some tensorflow callbacks\n","        self.checkpointer = ModelCheckpoint(os.path.join(\"results\", self.model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n","        self.tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", self.model_name))\n","\n","    def train(self, data):\n","        # train the model and save the weights whenever we see \n","        # a new optimal model using ModelCheckpoint\n","        history = self.model.fit(data[\"X_train\"], data[\"y_train\"],\n","                                 batch_size=self.BATCH_SIZE,\n","                                 epochs=self.EPOCHS,\n","                                 validation_data=(data[\"X_test\"], data[\"y_test\"]),\n","                                 callbacks=[self.checkpointer, self.tensorboard],\n","                                 verbose=1)\n","        self.load()\n","\n","    def load(self):\n","        # load optimal model weights from results folder\n","        model_path = os.path.join(\"results\", self.model_name) + \".h5\"\n","        self.model.load_weights(model_path)\n","\n","\n","\n","def runModel(ticker, modifier, trading, do_train=True):\n","    data = fetch_data(ticker)\n","\n","    data = modifier.change_data(data)\n","    \n","    pdata = PreparedData(ticker)\n","    modifier.change_prep(pdata)\n","        \n","    pdata.prepare(data)\n","    \n","    mod = RNNModel()\n","\n","    modifier.change_model(mod)\n","    mod.create(pdata)\n","    if not do_train:\n","        # TODO train only when not already trained\n","        mod.load()\n","    else:\n","        mod.train(pdata.data)\n","    res = TradingResult(mod.model, pdata, mod.LOSS)\n","    res.eval(trading)\n","    res.print()\n","    modifier.print(res)\n","    #df.set_index(['Ticker', 'Name'])\n","    return {'Ticker': ticker, 'Name': modifier.name, 'Buy': res.total_buy_profit,\n","               'Sell': res.total_sell_profit, 'Total': res.total_profit}\n","              \n","\n","\n","class NormalTrading:\n","    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n","    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n","\n","class NoModifier:\n","    name = 'Original'\n","    \n","    def change_prep(self, pdata):\n","        pass\n","\n","    def change_model(self, mod):\n","        pass\n","\n","    def change_data(self, data):\n","        return data\n","\n","    def print(self, res):\n","      pass\n","\n","\n","class AddDay(NoModifier):\n","    def __init__(self):\n","        self.name = 'Day'\n","    \n","    def change_prep(self, pdata):\n","        pdata.FEATURE_COLUMNS = pdata.FEATURE_COLUMNS + ['day']\n","        pdata.ticker_data_filename += '-withday'\n","        pdata.data_prefix += '-withday'\n","        pass\n","\n","\n","    def change_data(self, data):\n","        # add date as a column\n","        if \"date\" not in data.columns:\n","            data[\"date\"] = data.index\n","\n","        df = data.apply(lambda row: row.date.timetuple().tm_yday, axis = 1)\n","        return df.to_frame('day').join(data)\n","\n","class AddDayMonth(NoModifier):\n","    def __init__(self):\n","      self.name = 'DayMon'\n","    \n","    def change_prep(self, pdata):\n","        pdata.FEATURE_COLUMNS = pdata.FEATURE_COLUMNS + ['mday', 'month']\n","        pdata.ticker_data_filename += '-wdm'\n","        pdata.data_prefix += '-wdm'\n","        pass\n","\n","\n","    def change_data(self, data):\n","        # add date as a column\n","        if \"date\" not in data.columns:\n","            data[\"date\"] = data.index\n","\n","        dfd = data.apply(lambda row: row.date.timetuple().tm_mday, axis = 1)\n","        dfm = data.apply(lambda row: row.date.timetuple().tm_mon, axis = 1)\n","        df = dfd.to_frame('mday').join(data)\n","        return dfm.to_frame('month').join(df)\n","            \n","\n","def getStatFrame():\n","    return pd.DataFrame(columns=['Ticker', 'Name', 'Buy', 'Sell', 'Total'])\n","    \n","def runTicker(ticker, models = [NoModifier], df=getStatFrame()):\n","    for model in models:\n","        prepare()\n","        result = runModel(ticker, model, NormalTrading, True)\n","        df = df.append(result, ignore_index=True)\n","    return df\n","\n","\n","\n","def runTickers(tickers, models):\n","    df = getStatFrame()\n","    for ticker in tickers:\n","        df = runTicker(ticker, models, df)\n","    print(df)\n","    \n","# Todo: Combined model\n","# Model based on rate of return from previous day\n","# fix high, low based on adjusted price\n","# Incremental data load and training\n","\n","\n","# def combinedModel(tickers):\n","#     pdatas = []\n","#     for ticker in tickers:\n","#         data = fetch_data(ticker)\n","#         pdata = PrepareData()\n","#         pdata.prepare(ticker, data)\n","#         pdatas.add(pdata)\n","\n","#     combine = ProcessedData()\n","#     for pdata in pdatas:\n","#         combined.data['X_train'].append(ticker, pdata.data)\n","#         combined.data['X_test'].append(ticker, pdata.data)\n","#         y_train\n","#         y_test\n","#         combined.date_now = ''\n","#         combined.ticker_data_file_name = ''\n","\n","#     model.fit\n","    \n","#         combined.result['column_scaler] = virtual column scaler\n","        \n","        \n","        \n"],"metadata":{"id":"A26QGEg_eely","executionInfo":{"status":"ok","timestamp":1642415094273,"user_tz":480,"elapsed":2336,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["class AddMA(NoModifier):\n","  def __init__(self, num, col='adjclose'):\n","    self.period = num\n","    self.colname = f\"ma-{col}-{num}\"\n","    self.col = col\n","    self.name = self.colname\n","\n","  def change_prep(self, pdata):\n","        pdata.FEATURE_COLUMNS = pdata.FEATURE_COLUMNS + [self.colname]\n","        pdata.ticker_data_filename += f\"-w{self.colname}\"\n","        pdata.data_prefix += f\"-w{self.colname}\"\n","  \n","  def change_data(self, data):\n","      df = (data[self.col]\n","            .rolling(window=self.period)\n","            .mean()\n","            .to_frame(self.colname)\n","            .dropna())\n","      return df.join(data)\n"],"metadata":{"id":"AvfSlRthoUfk","executionInfo":{"status":"ok","timestamp":1642417377215,"user_tz":480,"elapsed":154,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":137,"outputs":[]},{"cell_type":"code","source":["class CropData(NoModifier):\n","    def __init__(self, num):\n","      self.num = num\n","      self.name = f\"Crop{num}\"\n","\n","    def change_data(self, data):\n","      return data.tail(self.num)"],"metadata":{"id":"W2Xu5-Wv3y9g","executionInfo":{"status":"ok","timestamp":1642417398025,"user_tz":480,"elapsed":143,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":139,"outputs":[]},{"cell_type":"code","source":["class FeatureSeq(NoModifier):\n","  def __init__(self, classes):\n","    self.name = 'seq'\n","    self.modifiers = classes \n","    for cls in classes:\n","      self.name += cls.name\n","    \n","  def change_prep(self, pdata):\n","    for cls in self.modifiers:\n","      cls.change_prep(pdata)\n","    \n","  def change_model(self, mod):\n","    for obj in self.modifiers:\n","      obj.change_model(mod)\n","\n","  def change_data(self, data):\n","    for cls in self.modifiers:\n","      data = cls.change_data(data)\n","    return data\n","\n","  def print(self, res):\n","    for cls in self.modifiers:\n","      cls.print(res)"],"metadata":{"id":"esnV_u7drBTz","executionInfo":{"status":"ok","timestamp":1642417219091,"user_tz":480,"elapsed":150,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":132,"outputs":[]},{"cell_type":"code","source":["class RateReturnOnly(NoModifier):\n","\n","  def __init__(self):\n","    self.name = 'RROnly'\n","    # =['adjclose', 'volume', 'open', 'high', 'low']\n","\n","  def change_prep(self, pdata):\n","        pdata.ticker_data_filename += f\"-w{self.name}\"\n","        pdata.data_prefix += f\"-w{self.name}\"\n","  \n","  def change_data(self, data):\n","    sdata = data.rolling(200).mean()\n","    self.lastref = sdata.tail(1).adjclose.item()\n","    newdata = data\n","    newdata['adjclose'] = (data['adjclose']-sdata['adjclose'])/sdata['adjclose']\n","    newdata['volume'] = (data['volume']-sdata['volume'])/sdata['volume']\n","    newdata['open'] = data['open']/data['adjclose']\n","    newdata['high'] = data['high']/data['adjclose']-1\n","    newdata['low'] = 1-data['low']/data['adjclose']\n","    newdata['close'] =  data['close']/data['adjclose']\n","    newdata['ticker'] = data['ticker']\n","    newdata.dropna(inplace=True)\n","    return newdata.tail(2000)\n","  \n","  def print(self, res):\n","      print(f\"Last 200 dma {self.lastref}\")\n","      print(f\"Future price {self.lastref * (1 + res.future_price)}\")\n","\n"],"metadata":{"id":"BwBaVCMV0zYh","executionInfo":{"status":"ok","timestamp":1642416958336,"user_tz":480,"elapsed":134,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":127,"outputs":[]},{"cell_type":"code","source":["testdata = fetch_data('NET')"],"metadata":{"id":"doIeuZpAkagQ","executionInfo":{"status":"ok","timestamp":1642416273540,"user_tz":480,"elapsed":154,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["testdata.tail(1).adjclose.item()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2a6vFU1oag-","executionInfo":{"status":"ok","timestamp":1642416293025,"user_tz":480,"elapsed":133,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"da6b6d17-0c52-4dbf-de85-ed5e493dfc4d"},"execution_count":114,"outputs":[{"output_type":"execute_result","data":{"text/plain":["100.29000091552734"]},"metadata":{},"execution_count":114}]},{"cell_type":"code","source":["obj = RateReturnOnly()\n","testdf = obj.change_data(testdata)\n","testdata.tail(6), testdf.tail(6)\n","print(obj.lastref)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bn7BJKbdqNjk","executionInfo":{"status":"ok","timestamp":1642416332572,"user_tz":480,"elapsed":163,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"fbaa5f71-5a8b-4d8b-8074-a160c78c7b90"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stdout","text":["100.29000091552734\n"]}]},{"cell_type":"code","source":["mod = FeatureSeq([AddDayMonth, AddMA(200)])\n","newdata = mod.change_data(testdata)\n","newdata.tail(10)\n","tpdata = PreparedData('AMZN')\n","tpdata.prepare(newdata)\n","mod.change_prep(tpdata)"],"metadata":{"id":"JI9jnI0dkvkF","executionInfo":{"status":"ok","timestamp":1642400690032,"user_tz":480,"elapsed":661,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":62,"outputs":[]},{"cell_type":"code","source":["tpdata.data[\"X_test\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cKjlP6jiHuKq","executionInfo":{"status":"ok","timestamp":1642407651448,"user_tz":480,"elapsed":182,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"24fd17d4-ae5d-4316-9692-285cbf6b3f6d"},"execution_count":123,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.01989295, 0.05625344, 0.02001557, 0.01982755, 0.01990637],\n","        [0.01996543, 0.05777111, 0.01998347, 0.02013815, 0.02022604],\n","        [0.02030633, 0.04243005, 0.01997544, 0.02008771, 0.02026127],\n","        ...,\n","        [0.01871994, 0.03496349, 0.01874754, 0.01890108, 0.01882816],\n","        [0.01963258, 0.06682881, 0.01899633, 0.01949041, 0.01923723],\n","        [0.01935879, 0.05340659, 0.01943238, 0.01925415, 0.01929412]],\n","\n","       [[0.20780095, 0.02570376, 0.20754449, 0.20590764, 0.20795225],\n","        [0.20786807, 0.00923943, 0.20882055, 0.20723496, 0.2092472 ],\n","        [0.2042175 , 0.03438929, 0.20627646, 0.20464669, 0.20554659],\n","        ...,\n","        [0.22386082, 0.06253583, 0.22222045, 0.22203197, 0.22289017],\n","        [0.21587518, 0.09654618, 0.21422972, 0.21561037, 0.21631792],\n","        [0.21518801, 0.02915477, 0.21505368, 0.21359815, 0.216047  ]],\n","\n","       [[0.01914673, 0.0462426 , 0.01953672, 0.01935237, 0.01923452],\n","        [0.01967016, 0.04624937, 0.01896423, 0.01945856, 0.01928328],\n","        [0.01950911, 0.05867688, 0.01997009, 0.01983021, 0.01975195],\n","        ...,\n","        [0.0220833 , 0.04373313, 0.02240716, 0.02244504, 0.02236081],\n","        [0.02232756, 0.05958072, 0.02197379, 0.0221663 , 0.02207635],\n","        [0.02192493, 0.07138279, 0.02189353, 0.02216099, 0.0219409 ]],\n","\n","       ...,\n","\n","       [[0.00746489, 0.04206272, 0.00738077, 0.00749938, 0.00756919],\n","        [0.00741657, 0.03204028, 0.00751453, 0.00752592, 0.00758003],\n","        [0.00738168, 0.04370993, 0.0073781 , 0.00745159, 0.0074825 ],\n","        ...,\n","        [0.00589997, 0.06530147, 0.00590141, 0.00585084, 0.0059627 ],\n","        [0.00620598, 0.08327863, 0.00589873, 0.00627824, 0.00604668],\n","        [0.00621403, 0.04946741, 0.00620103, 0.0061402 , 0.00615234]],\n","\n","       [[0.00994245, 0.06072912, 0.01007466, 0.00995492, 0.01002633],\n","        [0.00993171, 0.03942274, 0.00992753, 0.00992307, 0.01004259],\n","        [0.00967402, 0.05882478, 0.00984995, 0.00992572, 0.00984753],\n","        ...,\n","        [0.01027798, 0.03875574, 0.01018435, 0.01033985, 0.01041373],\n","        [0.00997735, 0.06705888, 0.01008001, 0.01012748, 0.01009406],\n","        [0.0096445 , 0.08130953, 0.00991148, 0.01010889, 0.00979877]],\n","\n","       [[0.4228843 , 0.01193161, 0.42374048, 0.42044026, 0.42525628],\n","        [0.42837626, 0.02397922, 0.4187005 , 0.42361784, 0.42284247],\n","        [0.42870104, 0.02463752, 0.42591804, 0.4253115 , 0.4288133 ],\n","        ...,\n","        [0.47598404, 0.05491653, 0.48725954, 0.48404822, 0.47693753],\n","        [0.47550625, 0.04695504, 0.47633415, 0.4767028 , 0.46970427],\n","        [0.4808023 , 0.03162751, 0.47566804, 0.47580287, 0.47964662]]],\n","      dtype=float32)"]},"metadata":{},"execution_count":123}]},{"cell_type":"code","source":["EPOCHS=20"],"metadata":{"id":"EWXrBT9NezcK","executionInfo":{"status":"ok","timestamp":1642416502832,"user_tz":480,"elapsed":144,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}}},"execution_count":122,"outputs":[]},{"cell_type":"code","source":["#runTicker('AMZN', [NoModifier(), AddDayMonth(),AddMA(200)])\n","#runTicker('MSFT', [FeatureSeq([AddDayMonth(), AddMA(200), CropData(2000)])])\n","modlist = [FeatureSeq([AddDayMonth(), AddMA(200), CropData(2000)]), FeatureSeq([RateReturnOnly(), AddDayMonth()])]\n","runTicker('PTON', modlist)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"isXbLIw52XdI","executionInfo":{"status":"ok","timestamp":1642417434428,"user_tz":480,"elapsed":33206,"user":{"displayName":"Ahsan Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghqm5jCaiW5JcNoKIVfwqG-0dZvFh8_tz3MunNi=s64","userId":"05755352427688583985"}},"outputId":"a78b6ee6-9140-4da3-fc20-717580b794f0"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","4/4 [==============================] - ETA: 0s - loss: 0.0751 - mean_absolute_error: 0.3083\n","Epoch 00001: val_loss improved from inf to 0.03123, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 6s 419ms/step - loss: 0.0751 - mean_absolute_error: 0.3083 - val_loss: 0.0312 - val_mean_absolute_error: 0.2170\n","Epoch 2/20\n","4/4 [==============================] - ETA: 0s - loss: 0.0201 - mean_absolute_error: 0.1637\n","Epoch 00002: val_loss improved from 0.03123 to 0.01009, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 75ms/step - loss: 0.0201 - mean_absolute_error: 0.1637 - val_loss: 0.0101 - val_mean_absolute_error: 0.1176\n","Epoch 3/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0198 - mean_absolute_error: 0.1639\n","Epoch 00003: val_loss did not improve from 0.01009\n","4/4 [==============================] - 0s 60ms/step - loss: 0.0174 - mean_absolute_error: 0.1530 - val_loss: 0.0115 - val_mean_absolute_error: 0.1213\n","Epoch 4/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0140 - mean_absolute_error: 0.1328\n","Epoch 00004: val_loss did not improve from 0.01009\n","4/4 [==============================] - 0s 61ms/step - loss: 0.0142 - mean_absolute_error: 0.1328 - val_loss: 0.0144 - val_mean_absolute_error: 0.1397\n","Epoch 5/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0123 - mean_absolute_error: 0.1249\n","Epoch 00005: val_loss improved from 0.01009 to 0.00966, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0118 - mean_absolute_error: 0.1217 - val_loss: 0.0097 - val_mean_absolute_error: 0.1127\n","Epoch 6/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0125 - mean_absolute_error: 0.1293\n","Epoch 00006: val_loss improved from 0.00966 to 0.00884, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 65ms/step - loss: 0.0119 - mean_absolute_error: 0.1252 - val_loss: 0.0088 - val_mean_absolute_error: 0.1067\n","Epoch 7/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0094 - mean_absolute_error: 0.1068\n","Epoch 00007: val_loss did not improve from 0.00884\n","4/4 [==============================] - 0s 57ms/step - loss: 0.0100 - mean_absolute_error: 0.1106 - val_loss: 0.0106 - val_mean_absolute_error: 0.1172\n","Epoch 8/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.1075\n","Epoch 00008: val_loss improved from 0.00884 to 0.00871, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 63ms/step - loss: 0.0098 - mean_absolute_error: 0.1116 - val_loss: 0.0087 - val_mean_absolute_error: 0.1050\n","Epoch 9/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0093 - mean_absolute_error: 0.1054\n","Epoch 00009: val_loss improved from 0.00871 to 0.00843, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 63ms/step - loss: 0.0096 - mean_absolute_error: 0.1081 - val_loss: 0.0084 - val_mean_absolute_error: 0.1032\n","Epoch 10/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0082 - mean_absolute_error: 0.0988\n","Epoch 00010: val_loss did not improve from 0.00843\n","4/4 [==============================] - 0s 58ms/step - loss: 0.0088 - mean_absolute_error: 0.1020 - val_loss: 0.0091 - val_mean_absolute_error: 0.1093\n","Epoch 11/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0096 - mean_absolute_error: 0.1093\n","Epoch 00011: val_loss improved from 0.00843 to 0.00842, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0096 - mean_absolute_error: 0.1087 - val_loss: 0.0084 - val_mean_absolute_error: 0.1051\n","Epoch 12/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0076 - mean_absolute_error: 0.0981\n","Epoch 00012: val_loss improved from 0.00842 to 0.00813, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 62ms/step - loss: 0.0084 - mean_absolute_error: 0.1021 - val_loss: 0.0081 - val_mean_absolute_error: 0.1035\n","Epoch 13/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1041\n","Epoch 00013: val_loss did not improve from 0.00813\n","4/4 [==============================] - 0s 55ms/step - loss: 0.0091 - mean_absolute_error: 0.1049 - val_loss: 0.0086 - val_mean_absolute_error: 0.1068\n","Epoch 14/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0080 - mean_absolute_error: 0.1027\n","Epoch 00014: val_loss improved from 0.00813 to 0.00791, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 63ms/step - loss: 0.0086 - mean_absolute_error: 0.1073 - val_loss: 0.0079 - val_mean_absolute_error: 0.1022\n","Epoch 15/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1047\n","Epoch 00015: val_loss improved from 0.00791 to 0.00786, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 66ms/step - loss: 0.0092 - mean_absolute_error: 0.1076 - val_loss: 0.0079 - val_mean_absolute_error: 0.1013\n","Epoch 16/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0087 - mean_absolute_error: 0.1066\n","Epoch 00016: val_loss did not improve from 0.00786\n","4/4 [==============================] - 0s 57ms/step - loss: 0.0079 - mean_absolute_error: 0.1017 - val_loss: 0.0085 - val_mean_absolute_error: 0.1072\n","Epoch 17/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0078 - mean_absolute_error: 0.1014\n","Epoch 00017: val_loss improved from 0.00786 to 0.00776, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 77ms/step - loss: 0.0080 - mean_absolute_error: 0.1036 - val_loss: 0.0078 - val_mean_absolute_error: 0.1014\n","Epoch 18/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0083 - mean_absolute_error: 0.1009\n","Epoch 00018: val_loss improved from 0.00776 to 0.00766, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 65ms/step - loss: 0.0085 - mean_absolute_error: 0.1020 - val_loss: 0.0077 - val_mean_absolute_error: 0.1006\n","Epoch 19/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0079 - mean_absolute_error: 0.1052\n","Epoch 00019: val_loss improved from 0.00766 to 0.00765, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 62ms/step - loss: 0.0077 - mean_absolute_error: 0.1026 - val_loss: 0.0076 - val_mean_absolute_error: 0.1009\n","Epoch 20/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0089 - mean_absolute_error: 0.1034\n","Epoch 00020: val_loss improved from 0.00765 to 0.00725, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wdm-wma-adjclose-200-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0083 - mean_absolute_error: 0.1019 - val_loss: 0.0072 - val_mean_absolute_error: 0.0974\n","Ticker PTON\n","Future price after 15 days is 26.23$\n","huber_loss_loss: 0.007248006761074066\n","Mean Absolute Error: 44.58590319096354\n","Accuracy score: 0.6875\n","Total buy profit: 167.09999084472656\n","Total sell profit: 249.45000457763672\n","Total profit: 416.5499954223633\n","Profit per trade: 6.508593678474426\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:433: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","4/4 [==============================] - ETA: 0s - loss: 0.0493 - mean_absolute_error: 0.2460\n","Epoch 00001: val_loss improved from inf to 0.02648, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 6s 415ms/step - loss: 0.0493 - mean_absolute_error: 0.2460 - val_loss: 0.0265 - val_mean_absolute_error: 0.1839\n","Epoch 2/20\n","4/4 [==============================] - ETA: 0s - loss: 0.0156 - mean_absolute_error: 0.1259\n","Epoch 00002: val_loss improved from 0.02648 to 0.00803, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 76ms/step - loss: 0.0156 - mean_absolute_error: 0.1259 - val_loss: 0.0080 - val_mean_absolute_error: 0.1058\n","Epoch 3/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0119 - mean_absolute_error: 0.1290\n","Epoch 00003: val_loss did not improve from 0.00803\n","4/4 [==============================] - 0s 63ms/step - loss: 0.0112 - mean_absolute_error: 0.1221 - val_loss: 0.0097 - val_mean_absolute_error: 0.1110\n","Epoch 4/20\n","4/4 [==============================] - ETA: 0s - loss: 0.0092 - mean_absolute_error: 0.1025\n","Epoch 00004: val_loss improved from 0.00803 to 0.00469, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 71ms/step - loss: 0.0092 - mean_absolute_error: 0.1025 - val_loss: 0.0047 - val_mean_absolute_error: 0.0745\n","Epoch 5/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0059 - mean_absolute_error: 0.0852\n","Epoch 00005: val_loss did not improve from 0.00469\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0062 - mean_absolute_error: 0.0879 - val_loss: 0.0051 - val_mean_absolute_error: 0.0774\n","Epoch 6/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0781\n","Epoch 00006: val_loss did not improve from 0.00469\n","4/4 [==============================] - 0s 61ms/step - loss: 0.0056 - mean_absolute_error: 0.0829 - val_loss: 0.0061 - val_mean_absolute_error: 0.0859\n","Epoch 7/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0058 - mean_absolute_error: 0.0821\n","Epoch 00007: val_loss did not improve from 0.00469\n","4/4 [==============================] - 0s 61ms/step - loss: 0.0055 - mean_absolute_error: 0.0803 - val_loss: 0.0048 - val_mean_absolute_error: 0.0744\n","Epoch 8/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0055 - mean_absolute_error: 0.0789\n","Epoch 00008: val_loss improved from 0.00469 to 0.00433, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0057 - mean_absolute_error: 0.0813 - val_loss: 0.0043 - val_mean_absolute_error: 0.0679\n","Epoch 9/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0751\n","Epoch 00009: val_loss improved from 0.00433 to 0.00428, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 63ms/step - loss: 0.0048 - mean_absolute_error: 0.0738 - val_loss: 0.0043 - val_mean_absolute_error: 0.0679\n","Epoch 10/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0041 - mean_absolute_error: 0.0663\n","Epoch 00010: val_loss improved from 0.00428 to 0.00406, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 65ms/step - loss: 0.0041 - mean_absolute_error: 0.0672 - val_loss: 0.0041 - val_mean_absolute_error: 0.0660\n","Epoch 11/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0664\n","Epoch 00011: val_loss improved from 0.00406 to 0.00394, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 62ms/step - loss: 0.0043 - mean_absolute_error: 0.0681 - val_loss: 0.0039 - val_mean_absolute_error: 0.0660\n","Epoch 12/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0660\n","Epoch 00012: val_loss improved from 0.00394 to 0.00368, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 65ms/step - loss: 0.0040 - mean_absolute_error: 0.0678 - val_loss: 0.0037 - val_mean_absolute_error: 0.0648\n","Epoch 13/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0038 - mean_absolute_error: 0.0645\n","Epoch 00013: val_loss improved from 0.00368 to 0.00348, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 63ms/step - loss: 0.0038 - mean_absolute_error: 0.0643 - val_loss: 0.0035 - val_mean_absolute_error: 0.0616\n","Epoch 14/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0036 - mean_absolute_error: 0.0648\n","Epoch 00014: val_loss did not improve from 0.00348\n","4/4 [==============================] - 0s 57ms/step - loss: 0.0037 - mean_absolute_error: 0.0650 - val_loss: 0.0036 - val_mean_absolute_error: 0.0622\n","Epoch 15/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0656\n","Epoch 00015: val_loss improved from 0.00348 to 0.00338, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0040 - mean_absolute_error: 0.0659 - val_loss: 0.0034 - val_mean_absolute_error: 0.0615\n","Epoch 16/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0039 - mean_absolute_error: 0.0682\n","Epoch 00016: val_loss did not improve from 0.00338\n","4/4 [==============================] - 0s 58ms/step - loss: 0.0034 - mean_absolute_error: 0.0644 - val_loss: 0.0034 - val_mean_absolute_error: 0.0619\n","Epoch 17/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0033 - mean_absolute_error: 0.0623\n","Epoch 00017: val_loss did not improve from 0.00338\n","4/4 [==============================] - 0s 59ms/step - loss: 0.0032 - mean_absolute_error: 0.0621 - val_loss: 0.0034 - val_mean_absolute_error: 0.0634\n","Epoch 18/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0610\n","Epoch 00018: val_loss did not improve from 0.00338\n","4/4 [==============================] - 0s 57ms/step - loss: 0.0034 - mean_absolute_error: 0.0630 - val_loss: 0.0035 - val_mean_absolute_error: 0.0630\n","Epoch 19/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0032 - mean_absolute_error: 0.0634\n","Epoch 00019: val_loss improved from 0.00338 to 0.00326, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 62ms/step - loss: 0.0029 - mean_absolute_error: 0.0601 - val_loss: 0.0033 - val_mean_absolute_error: 0.0594\n","Epoch 20/20\n","3/4 [=====================>........] - ETA: 0s - loss: 0.0042 - mean_absolute_error: 0.0688\n","Epoch 00020: val_loss improved from 0.00326 to 0.00312, saving model to results/2022-01-17_PTON-sh-1-sc-1-sbd-0-seq-50-step-15-wRROnly-wdm-model-huber_loss-adam-LSTM-layers-2-units-256.h5\n","4/4 [==============================] - 0s 64ms/step - loss: 0.0039 - mean_absolute_error: 0.0677 - val_loss: 0.0031 - val_mean_absolute_error: 0.0597\n","Ticker PTON\n","Future price after 15 days is -0.79$\n","huber_loss_loss: 0.0031222060788422823\n","Mean Absolute Error: -0.5137975503285542\n","Accuracy score: 0.65625\n","Total buy profit: 0.6993138635109151\n","Total sell profit: 6.649238843510605\n","Total profit: 7.34855270702152\n","Profit per trade: 0.11482113604721125\n","Last 200 dma 89.57470004081726\n","Future price 18.69240870918654\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-ce97f16a-ec46-410e-b7b1-ab2a2e0dad31\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Ticker</th>\n","      <th>Name</th>\n","      <th>Buy</th>\n","      <th>Sell</th>\n","      <th>Total</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>PTON</td>\n","      <td>seqDayMonma-adjclose-200Crop2000</td>\n","      <td>167.099991</td>\n","      <td>249.450005</td>\n","      <td>416.549995</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>PTON</td>\n","      <td>seqRROnlyDayMon</td>\n","      <td>0.699314</td>\n","      <td>6.649239</td>\n","      <td>7.348553</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce97f16a-ec46-410e-b7b1-ab2a2e0dad31')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ce97f16a-ec46-410e-b7b1-ab2a2e0dad31 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ce97f16a-ec46-410e-b7b1-ab2a2e0dad31');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  Ticker                              Name         Buy        Sell       Total\n","0   PTON  seqDayMonma-adjclose-200Crop2000  167.099991  249.450005  416.549995\n","1   PTON                   seqRROnlyDayMon    0.699314    6.649239    7.348553"]},"metadata":{},"execution_count":140}]},{"cell_type":"code","source":[""],"metadata":{"id":"cvuW9e2Fgqdl"},"execution_count":null,"outputs":[]}]}