{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockML.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPgkAeUwUfGUWybTjT/Z6iQ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iRWFgIbnzajB"
      },
      "outputs": [],
      "source": [
        "pip install -q yahoo_fin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir -p data results log"
      ],
      "metadata": {
        "id": "0MuPGKaH3W59"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "4LpuYsu4h3lA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def prepare():\n",
        "    # set seed, so we can get the same results after rerunning several times\n",
        "    np.random.seed(314)\n",
        "    tf.random.set_seed(314)\n",
        "    random.seed(314)\n",
        "\n",
        "\n",
        "def shuffle_in_unison(a, b):\n",
        "    # shuffle two arrays in the same way\n",
        "    state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(state)\n",
        "    np.random.shuffle(b)\n",
        "\n",
        "# Following two functions code mainly from https://www.thepythoncode.com/article/stock-price-prediction-in-python-using-tensorflow-2-and-keras\n",
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    \"\"\"\n",
        "    Loads data from Yahoo Finance source, as well as scaling, shuffling, normalizing and splitting.\n",
        "    Params:\n",
        "        ticker (str/pd.DataFrame): the ticker you want to load, examples include AAPL, TESL, etc.\n",
        "        n_steps (int): the historical sequence length (i.e window size) used to predict, default is 50\n",
        "        scale (bool): whether to scale prices from 0 to 1, default is True\n",
        "        shuffle (bool): whether to shuffle the dataset (both training & testing), default is True\n",
        "        lookup_step (int): the future lookup step to predict, default is 1 (e.g next day)\n",
        "        split_by_date (bool): whether we split the dataset into training/testing by date, setting it \n",
        "            to False will split datasets in a random way\n",
        "        test_size (float): ratio for test data, default is 0.2 (20% testing data)\n",
        "        feature_columns (list): the list of features to use to feed into the model, default is everything grabbed from yahoo_fin\n",
        "    \"\"\"\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    # add date as a column\n",
        "    if \"date\" not in df.columns:\n",
        "        df[\"date\"] = df.index\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
        "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
        "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
        "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    if split_by_date:\n",
        "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
        "        train_samples = int((1 - test_size) * len(X))\n",
        "        result[\"X_train\"] = X[:train_samples]\n",
        "        result[\"y_train\"] = y[:train_samples]\n",
        "        result[\"X_test\"]  = X[train_samples:]\n",
        "        result[\"y_test\"]  = y[train_samples:]\n",
        "        if shuffle:\n",
        "            # shuffle the datasets for training (if shuffle parameter is set)\n",
        "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
        "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
        "    else:    \n",
        "        # split the dataset randomly\n",
        "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "    # get the list of test set dates\n",
        "    dates = result[\"X_test\"][:, -1, -1]\n",
        "    # retrieve test features from the original dataframe\n",
        "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
        "    # remove duplicated dates in the testing dataframe\n",
        "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
        "    # remove dates from the training/testing sets & convert to float32\n",
        "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
        "    return result\n",
        "\n",
        "def get_final_df(model, data, scale, lookup_step, trade):\n",
        "    \"\"\"\n",
        "    This function takes the `model` and `data` dict to \n",
        "    construct a final dataframe that includes the features along \n",
        "    with true and predicted prices of the testing dataset\n",
        "    \"\"\"\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_test = data[\"y_test\"]\n",
        "    # perform prediction and get prices\n",
        "    y_pred = model.predict(X_test)\n",
        "    if scale:\n",
        "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    test_df = data[\"test_df\"]\n",
        "    # add predicted future prices to the dataframe\n",
        "    test_df[f\"adjclose_{lookup_step}\"] = y_pred\n",
        "    # add true future prices to the dataframe\n",
        "    test_df[f\"true_adjclose_{lookup_step}\"] = y_test\n",
        "    # sort the dataframe by date\n",
        "    test_df.sort_index(inplace=True)\n",
        "    final_df = test_df\n",
        "    # add the buy profit column\n",
        "    final_df[\"buy_profit\"] = list(map(trade.buy_profit, \n",
        "                                    final_df[\"adjclose\"], \n",
        "                                    final_df[f\"adjclose_{lookup_step}\"], \n",
        "                                    final_df[f\"true_adjclose_{lookup_step}\"])\n",
        "                                    # since we don't have profit for last sequence, add 0's\n",
        "                                    )\n",
        "    # add the sell profit column\n",
        "    final_df[\"sell_profit\"] = list(map(trade.sell_profit, \n",
        "                                    final_df[\"adjclose\"], \n",
        "                                    final_df[f\"adjclose_{lookup_step}\"], \n",
        "                                    final_df[f\"true_adjclose_{lookup_step}\"])\n",
        "                                    # since we don't have profit for last sequence, add 0's\n",
        "                                    )\n",
        "    return final_df\n",
        "\n",
        "\n",
        "class TradingResult:\n",
        "    def __init__(self, model, prepdata, lossn):\n",
        "        self.model = model\n",
        "        self.pdata = prepdata\n",
        "        self.data = prepdata.data\n",
        "        self.LOSSN = lossn\n",
        "        \n",
        "    def predict(self):\n",
        "        # retrieve the last sequence from data\n",
        "        last_sequence = self.data[\"last_sequence\"][-self.pdata.N_STEPS:]\n",
        "        # expand dimension\n",
        "        last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "        # get the prediction (scaled from 0 to 1)\n",
        "        prediction = self.model.predict(last_sequence)\n",
        "        # get the price (by inverting the scaling)\n",
        "        if self.pdata.SCALE:\n",
        "            predicted_price = self.data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "        else:\n",
        "            predicted_price = prediction[0][0]\n",
        "        return predicted_price\n",
        "\n",
        "    def eval(self, trade):\n",
        "        # evaluate the model\n",
        "        loss, mae = self.model.evaluate(self.data[\"X_test\"], self.data[\"y_test\"], verbose=0)\n",
        "        # calculate the mean absolute error (inverse scaling)\n",
        "        if self.pdata.SCALE:\n",
        "            self.mean_absolute_error = self.data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "        else:\n",
        "            self.mean_absolute_error = mae\n",
        "            \n",
        "        # get the final dataframe for the testing set\n",
        "        final_df = get_final_df(self.model, self.data, self.pdata.SCALE, self.pdata.LOOKUP_STEP, trade)\n",
        "        # predict the future price\n",
        "        self.future_price = self.predict()\n",
        "        # we calculate the accuracy by counting the number of positive profits\n",
        "        self.accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
        "        # calculating total buy & sell profit\n",
        "        self.total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
        "        self.total_sell_profit = final_df[\"sell_profit\"].sum()\n",
        "        # total profit by adding sell & buy together\n",
        "        self.total_profit = self.total_buy_profit + self.total_sell_profit\n",
        "        # dividing total profit by number of testing samples (number of trades)\n",
        "        self.profit_per_trade = self.total_profit / len(final_df)\n",
        "        self.final_df = final_df\n",
        "        self.loss = loss\n",
        "\n",
        "    def print(self):\n",
        "        # printing metrics\n",
        "        print(f\"Ticker {self.pdata.ticker}\")\n",
        "        print(f\"Future price after {self.pdata.LOOKUP_STEP} days is {self.future_price:.2f}$\")\n",
        "        print(f\"{self.LOSSN}_loss:\", self.loss)\n",
        "        print(\"Mean Absolute Error:\", self.mean_absolute_error)\n",
        "        print(\"Accuracy score:\", self.accuracy_score)\n",
        "        print(\"Total buy profit:\", self.total_buy_profit)\n",
        "        print(\"Total sell profit:\", self.total_sell_profit)\n",
        "        print(\"Total profit:\", self.total_profit)\n",
        "        print(\"Profit per trade:\", self.profit_per_trade)\n",
        "        \n",
        "class PreparedData:\n",
        "    def __init__(self, ticker):\n",
        "        # Window size or the sequence length\n",
        "        self.N_STEPS = 50\n",
        "\t# Lookup step, 1 is the next day\n",
        "        self.LOOKUP_STEP = 15\n",
        "        # whether to scale feature columns & output price as well\n",
        "        self.SCALE = True\n",
        "        self.scale_str = f\"sc-{int(self.SCALE)}\"\n",
        "        # whether to shuffle the dataset\n",
        "        self.SHUFFLE = True\n",
        "        self.shuffle_str = f\"sh-{int(self.SHUFFLE)}\"\n",
        "        # whether to split the training/testing set by date\n",
        "        self.SPLIT_BY_DATE = False\n",
        "        self.split_by_date_str = f\"sbd-{int(self.SPLIT_BY_DATE)}\"\n",
        "        # test ratio size, 0.2 is 20%\n",
        "        self.TEST_SIZE = 0.2\n",
        "        # features to use\n",
        "        self.FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "        self.ticker = ticker\n",
        "        # date now\n",
        "        self.date_now = time.strftime(\"%Y-%m-%d\")        \n",
        "        self.ticker_data_filename = os.path.join(\"data\", f\"{self.ticker}_{self.date_now}.csv\")\n",
        "        self.data_prefix = f\"{self.ticker}-{self.shuffle_str}-{self.scale_str}-{self.split_by_date_str}-seq-{self.N_STEPS}-step-{self.LOOKUP_STEP}\"\n",
        "        \n",
        "    def prepare(self,  df):\n",
        "        # load the data\n",
        "        self.data = load_data(df, self.N_STEPS, scale=self.SCALE, split_by_date=self.SPLIT_BY_DATE, \n",
        "                shuffle=self.SHUFFLE, lookup_step=self.LOOKUP_STEP, test_size=self.TEST_SIZE, \n",
        "                feature_columns=self.FEATURE_COLUMNS)\n",
        "\n",
        "        # save the dataframe\n",
        "        self.data[\"df\"].to_csv(self.ticker_data_filename)\n",
        "\n",
        "\n",
        "def fetch_data(ticker):\n",
        "# see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    else:\n",
        "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model\n",
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "class RNNModel:\n",
        "    def __init__(self):\n",
        "        self.date_now = time.strftime(\"%Y-%m-%d\")\n",
        "        ### model parameters\n",
        "        self.N_LAYERS = 2\n",
        "        # LSTM cell\n",
        "        self.CELL = LSTM\n",
        "        # 256 LSTM neurons\n",
        "        self.UNITS = 256\n",
        "        # 40% dropout\n",
        "        self.DROPOUT = 0.4\n",
        "        # whether to use bidirectional RNNs\n",
        "        self.BIDIRECTIONAL = False\n",
        "        ### training parameters\n",
        "        # mean absolute error loss\n",
        "        # LOSS = \"mae\"\n",
        "        # huber loss\n",
        "        self.LOSS = \"huber_loss\"\n",
        "        self.OPTIMIZER = \"adam\"\n",
        "        self.BATCH_SIZE = 64\n",
        "        self.EPOCHS = EPOCHS # 500\n",
        "\n",
        "    def create(self, prepdata):\n",
        "        # model name to save, making it as unique as possible based on parameters\n",
        "        self.model_name = f\"{prepdata.data_prefix}-model-{self.LOSS}-{self.OPTIMIZER}-{self.CELL.__name__}-layers-{self.N_LAYERS}-units-{self.UNITS}\"\n",
        "        self.model_path = os.path.join(\"results\", self.model_name + \".h5\")\n",
        "        if self.BIDIRECTIONAL:\n",
        "            self.model_name += \"-b\"\n",
        "\n",
        "        # create these folders if they does not exist\n",
        "        if not os.path.isdir(\"results\"):\n",
        "            os.mkdir(\"results\")\n",
        "        if not os.path.isdir(\"logs\"):\n",
        "            os.mkdir(\"logs\")\n",
        "        if not os.path.isdir(\"data\"):\n",
        "            os.mkdir(\"data\")\n",
        "\n",
        "        self.model = create_model(prepdata.N_STEPS, len(prepdata.FEATURE_COLUMNS), loss=self.LOSS, units=self.UNITS, cell=self.CELL, n_layers=self.N_LAYERS,\n",
        "                    dropout=self.DROPOUT, optimizer=self.OPTIMIZER, bidirectional=self.BIDIRECTIONAL)\n",
        "        # some tensorflow callbacks\n",
        "        self.checkpointer = ModelCheckpoint(self.model_path, save_weights_only=True, save_best_only=True, verbose=1)\n",
        "        self.tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", self.model_name))\n",
        "        self.earlystopping = EarlyStopping(monitor='loss', patience=5)\n",
        "\n",
        "    def train(self, data):\n",
        "        # train the model and save the weights whenever we see \n",
        "        # a new optimal model using ModelCheckpoint\n",
        "        history = self.model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                                 batch_size=self.BATCH_SIZE,\n",
        "                                 epochs=self.EPOCHS,\n",
        "                                 validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                                 callbacks=[self.checkpointer, self.tensorboard, self.earlystopping],\n",
        "                                 verbose=1)\n",
        "        self.load()\n",
        "\n",
        "    def load(self):\n",
        "        # load optimal model weights from results folder\n",
        "        print(f\"loading model from {self.model_path}\")\n",
        "        self.model.load_weights(self.model_path)\n",
        "\n",
        "\n",
        "\n",
        "def runModel(ticker, modifier, trading, do_train=True):\n",
        "    data = fetch_data(ticker)\n",
        "\n",
        "    data = modifier.change_data(data)\n",
        "    \n",
        "    pdata = PreparedData(ticker)\n",
        "    modifier.change_prep(pdata)\n",
        "        \n",
        "    pdata.prepare(data)\n",
        "    \n",
        "    mod = RNNModel()\n",
        "\n",
        "    modifier.change_model(mod)\n",
        "    mod.create(pdata)\n",
        "    if not do_train:\n",
        "        # TODO train only when not already trained\n",
        "        mod.load()\n",
        "    else:\n",
        "        mod.train(pdata.data)\n",
        "    res = TradingResult(mod.model, pdata, mod.LOSS)\n",
        "    res.eval(trading)\n",
        "    res.print()\n",
        "    modifier.print(res)\n",
        "    #df.set_index(['Ticker', 'Name'])\n",
        "    return {'Ticker': ticker, 'Name': modifier.name, 'Buy': res.total_buy_profit,\n",
        "               'Sell': res.total_sell_profit, 'Total': res.total_profit}\n",
        "              \n",
        "\n",
        "\n",
        "class NormalTrading:\n",
        "    buy_profit  = lambda current, pred_future, true_future: true_future - current if pred_future > current else 0\n",
        "    sell_profit = lambda current, pred_future, true_future: current - true_future if pred_future < current else 0\n",
        "\n",
        "class NoModifier:\n",
        "    name = 'Original'\n",
        "    \n",
        "    def change_prep(self, pdata):\n",
        "        pass\n",
        "\n",
        "    def change_model(self, mod):\n",
        "        pass\n",
        "\n",
        "    def change_data(self, data):\n",
        "        return data\n",
        "\n",
        "    def print(self, res):\n",
        "      pass\n",
        "\n",
        "\n",
        "class AddDay(NoModifier):\n",
        "    def __init__(self):\n",
        "        self.name = 'Day'\n",
        "    \n",
        "    def change_prep(self, pdata):\n",
        "        pdata.FEATURE_COLUMNS = pdata.FEATURE_COLUMNS + ['day']\n",
        "        pdata.ticker_data_filename += '-withday'\n",
        "        pdata.data_prefix += '-withday'\n",
        "        pass\n",
        "\n",
        "\n",
        "    def change_data(self, data):\n",
        "        # add date as a column\n",
        "        if \"date\" not in data.columns:\n",
        "            data[\"date\"] = data.index\n",
        "\n",
        "        df = data.apply(lambda row: row.date.timetuple().tm_yday, axis = 1)\n",
        "        return df.to_frame('day').join(data)\n",
        "\n",
        "class AddDayMonth(NoModifier):\n",
        "    def __init__(self):\n",
        "      self.name = 'DayMon'\n",
        "    \n",
        "    def change_prep(self, pdata):\n",
        "        pdata.FEATURE_COLUMNS = pdata.FEATURE_COLUMNS + ['mday', 'month']\n",
        "        pdata.ticker_data_filename += '-wdm'\n",
        "        pdata.data_prefix += '-wdm'\n",
        "        pass\n",
        "\n",
        "\n",
        "    def change_data(self, data):\n",
        "        # add date as a column\n",
        "        if \"date\" not in data.columns:\n",
        "            data[\"date\"] = data.index\n",
        "\n",
        "        dfd = data.apply(lambda row: row.date.timetuple().tm_mday, axis = 1)\n",
        "        dfm = data.apply(lambda row: row.date.timetuple().tm_mon, axis = 1)\n",
        "        df = dfd.to_frame('mday').join(data)\n",
        "        return dfm.to_frame('month').join(df)\n",
        "            \n",
        "\n",
        "def getStatFrame():\n",
        "    return pd.DataFrame(columns=['Ticker', 'Name', 'Buy', 'Sell', 'Total'])\n",
        "    \n",
        "def runTicker(ticker, models = [NoModifier], df=getStatFrame()):\n",
        "    for model in models:\n",
        "        prepare()\n",
        "        result = runModel(ticker, model, NormalTrading, True)\n",
        "        df = df.append(result, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "def runTickers(tickers, models):\n",
        "    df = getStatFrame()\n",
        "    for ticker in tickers:\n",
        "        df = runTicker(ticker, models, df)\n",
        "    print(df)\n",
        "  "
      ],
      "metadata": {
        "id": "A26QGEg_eely"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AddMA(NoModifier):\n",
        "  def __init__(self, num, col='adjclose'):\n",
        "    self.period = num\n",
        "    self.colname = f\"ma-{col}-{num}\"\n",
        "    self.col = col\n",
        "    self.name = self.colname\n",
        "\n",
        "  def change_prep(self, pdata):\n",
        "        pdata.FEATURE_COLUMNS = pdata.FEATURE_COLUMNS + [self.colname]\n",
        "        pdata.ticker_data_filename += f\"-w{self.colname}\"\n",
        "        pdata.data_prefix += f\"-w{self.colname}\"\n",
        "  \n",
        "  def change_data(self, data):\n",
        "      df = (data[self.col]\n",
        "            .rolling(window=self.period)\n",
        "            .mean()\n",
        "            .to_frame(self.colname)\n",
        "            .dropna())\n",
        "      return df.join(data)\n"
      ],
      "metadata": {
        "id": "AvfSlRthoUfk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CropData(NoModifier):\n",
        "    def __init__(self, num):\n",
        "      self.num = num\n",
        "      self.name = f\"Crop{num}\"\n",
        "\n",
        "    def change_data(self, data):\n",
        "      return data.tail(self.num)"
      ],
      "metadata": {
        "id": "W2Xu5-Wv3y9g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureSeq(NoModifier):\n",
        "  def __init__(self, classes):\n",
        "    self.name = 'seq'\n",
        "    self.modifiers = classes \n",
        "    for cls in classes:\n",
        "      self.name += cls.name\n",
        "    \n",
        "  def change_prep(self, pdata):\n",
        "    for cls in self.modifiers:\n",
        "      cls.change_prep(pdata)\n",
        "    \n",
        "  def change_model(self, mod):\n",
        "    for obj in self.modifiers:\n",
        "      obj.change_model(mod)\n",
        "\n",
        "  def change_data(self, data):\n",
        "    for cls in self.modifiers:\n",
        "      data = cls.change_data(data)\n",
        "    return data\n",
        "\n",
        "  def print(self, res):\n",
        "    for cls in self.modifiers:\n",
        "      cls.print(res)"
      ],
      "metadata": {
        "id": "esnV_u7drBTz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RateReturnOnly(NoModifier):\n",
        "\n",
        "  def __init__(self, next=None):\n",
        "    self.name = 'RROnly'\n",
        "    self.next = next\n",
        "    self.lastdata = None\n",
        "    # =['adjclose', 'volume', 'open', 'high', 'low']\n",
        "\n",
        "  def change_prep(self, pdata):\n",
        "        pdata.ticker_data_filename += f\"-w{self.name}\"\n",
        "        pdata.data_prefix += f\"-w{self.name}\"\n",
        "  \n",
        "  def change_data(self, data):\n",
        "    self.lastdata = data\n",
        "    sdata = data.rolling(window=200, min_periods=1).mean()\n",
        "\n",
        "    # only use last 5 years data\n",
        "    newdata = data.copy(deep=True).tail(1000)\n",
        "    newdata['adjclose'] = (data['adjclose']-sdata['adjclose'])/sdata['adjclose']\n",
        "    newdata['volume'] = (data['volume']-sdata['volume'])/sdata['volume']\n",
        "    newdata['open'] = data['open']/data['adjclose']\n",
        "    newdata['high'] = data['high']/data['adjclose']-1\n",
        "    newdata['low'] = 1-data['low']/data['adjclose']\n",
        "    newdata['close'] =  data['close']/data['adjclose']\n",
        "    newdata['ticker'] = data['ticker']\n",
        "    newdata.dropna(inplace=True)\n",
        "\n",
        "    if self.next is None:\n",
        "      return newdata\n",
        "    else:\n",
        "      return self.next.change_data(newdata)\n",
        "\n",
        "  def change_prep(self, pdata):\n",
        "    if self.lastdata is not None:\n",
        "      pdata.lastref = self.lastdata.rolling(window=200, min_periods=1).mean().tail(1).adjclose.item()\n",
        "      pdata.lastprice = self.lastdata.tail(1).adjclose.item()\n",
        "      print(f\"{pdata.ticker} \\t MA: {pdata.lastref:.2f}, \\t Price: {pdata.lastprice:.2f}\")\n",
        "\n",
        "    if self.next is not None:\n",
        "      self.next.change_prep(pdata)\n",
        "\n",
        "    \n",
        "  def change_model(self, mod):\n",
        "    if self.next is not None:\n",
        "      self.next.change_model(mod)\n",
        " \n",
        "  def predicted_price(self, pdata, res):\n",
        "    return pdata.lastref * (1 + res.future_price)\n",
        "  \n",
        "  def predicted_gain(self, pdata, res):\n",
        "    return self.predicted_price(pdata, res)/pdata.lastprice-1\n",
        "\n",
        "  def get_predict(self, data, future_price):\n",
        "      print(f\"Last 200 dma {self.lastref}\")\n",
        "      print(f\"Future price {self.predicted_price(res)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BwBaVCMV0zYh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def runModelCombined(tickers, name, modifier, do_train=True, trading=NormalTrading):\n",
        "  genpdata = PreparedData(name)\n",
        "  genpdata.data = {}\n",
        "  modifier.change_prep(genpdata)\n",
        "  pdatas = []\n",
        "  tickerset = set()\n",
        "  for ticker in tickers:\n",
        "    if ticker in tickerset:\n",
        "      raise ValueError(f\"Duplicate ticker {ticker}\")\n",
        "    tickerset.add(ticker)\n",
        "\n",
        "  for ticker in tickers:\n",
        "    data = fetch_data(ticker)\n",
        "    data = modifier.change_data(data)\n",
        "    pdata = PreparedData(ticker)\n",
        "    pdatas.append(pdata)\n",
        "    modifier.change_prep(pdata)\n",
        "    pdata.prepare(data)\n",
        "    mod = RNNModel()\n",
        "    modifier.change_model(mod)\n",
        "    mod.create(genpdata)\n",
        "\n",
        "    if  do_train:\n",
        "      if 'X_train' in genpdata.data:\n",
        "        print(f\"Adding {pdata.ticker} {pdata.data['X_train'].shape}\")\n",
        "        genpdata.data['X_train'] = np.concatenate((genpdata.data['X_train'], pdata.data['X_train']))\n",
        "        genpdata.data['y_train'] = np.concatenate((genpdata.data['y_train'], pdata.data['y_train']))\n",
        "        genpdata.data['X_test'] = np.concatenate((genpdata.data['X_test'], pdata.data['X_test']))\n",
        "        genpdata.data['y_test'] = np.concatenate((genpdata.data['y_test'], pdata.data['y_test']))\n",
        "\n",
        "      else:\n",
        "        genpdata.data['X_train'] = pdata.data['X_train']\n",
        "        genpdata.data['y_train'] = pdata.data['y_train']\n",
        "        genpdata.data['X_test'] = pdata.data['X_test']\n",
        "        genpdata.data['y_test'] = pdata.data['y_test']\n",
        "\n",
        "  if do_train:\n",
        "    mod.train(genpdata.data)\n",
        "  else:\n",
        "    mod.load()\n",
        "\n",
        "\n",
        "  df = getStatFrame()\n",
        "\n",
        "  for pdata in pdatas:\n",
        "    res = TradingResult(mod.model, pdata, mod.LOSS)\n",
        "    res.eval(trading)\n",
        "    res.print()\n",
        "    modifier.print(res)\n",
        "    df = df.append(\n",
        "        {'Ticker': pdata.ticker,\n",
        "         'Name': modifier.name,\n",
        "         'Buy': round(res.total_buy_profit,2),\n",
        "         'Sell': round(res.total_sell_profit,2),\n",
        "         'Total': round(res.total_profit,2),\n",
        "         'Last': round(pdata.lastprice,2),\n",
        "         'Predicted': round(modifier.predicted_price(pdata, res),2),\n",
        "         'Gain': round(modifier.predicted_gain(pdata, res),2)\n",
        "         }, ignore_index=True)\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "QRR5FeVTEKu1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = runTicker('GDX', [FeatureSeq([AddDayMonth(), AddMA(200), CropData(2000)])])\n",
        "df\n"
      ],
      "metadata": {
        "id": "JI9jnI0dkvkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#runTicker('AMZN', [NoModifier(), AddDayMonth(),AddMA(200)])\n",
        "#runTicker('MSFT', [FeatureSeq([AddDayMonth(), AddMA(200), CropData(2000)])])\n",
        "modlist = [FeatureSeq([AddDayMonth(), AddMA(200), CropData(2000)]), FeatureSeq([RateReturnOnly(), AddDayMonth()])]\n",
        "runTicker('PTON', modlist)"
      ],
      "metadata": {
        "id": "isXbLIw52XdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todos:\n",
        "\n",
        " \n",
        "\n",
        "1.   Load previously saved model before training\n",
        "2.   Allow eval only without test/train spliting\n",
        "3.   Incremental data load\n",
        "4.    Add S&P, QQQ etc to the model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4AuykWZdTyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=100\n",
        "tickers = ['RBLX', 'PTON', 'NET', 'SPOT', 'SNOW',\n",
        "            'WISH', 'SHOP',  'MELI',\n",
        "            'UBER', 'Z', 'TWTR', 'MDB', \n",
        "            'CRWD', 'GOGO', 'DOCN', 'DOCU', 'ONDS',\n",
        "            'AI', 'MQ', 'CFLT', 'STNE', 'MSCI', 'JWN', 'MPWR', 'CLOV', 'AFRM',\n",
        "            'FTCH', 'BKKT', 'HIVE', 'SFTBY', 'EVGO', 'AMSC',\n",
        "            'AMBA', 'INMD', 'ZM', 'BGFV', 'AHT', 'GLOB', 'SWAV', 'ERJ',\n",
        "            'TWLO', 'ATOM', 'GLBE',  'CRCT', 'U', \n",
        "            'MTCH', 'APO', 'OKTA', 'SMH', 'BILL', 'ABNB', 'BMBL']\n",
        "mod = RateReturnOnly(AddDayMonth())\n",
        "df = runModelCombined(tickers, 'ipos2a', mod, False)\n",
        "df.sort_values('Gain', ascending=False)"
      ],
      "metadata": {
        "id": "NRNq5x6mTG-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}